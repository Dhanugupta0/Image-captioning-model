# Image Captioning Models

Deep learning models for automatic image caption generation using CNN-LSTM and CLIP-GPT2 architectures.

## ðŸš€ Models Implemented

- **CNN-LSTM**: Traditional approach using CNN for feature extraction and LSTM for sequence generation
- **CLIP-GPT2**: Modern approach combining CLIP vision encoder with GPT-2 language model

## ðŸ“Š Dataset

- **Flickr30k**: 31,783 images with 158,915 captions
- Each image has 5 different captions for training diversity
